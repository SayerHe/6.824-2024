# L1

## 0. 引入

由于 mit 6.824 中选用的 rpc 通信框架为 golang 内置的 net/rpc，无法实现**服务端push**操作。因此，coordinator 并不能发挥全部的调度作用，例如 当一些任务超时时，coordinator 无法立即 调度起空闲的 worker 来重新执行任务，只能等下一个 worker 轮询时将 失败的任务 重新分配。

在此背景下，服务端有两种架构选择：

* 由于 coordinator 无法调度各 worker，因此不关心、不维护 worker 的状态，只需要维护 task 的状态。这种架构下，依靠客户端的不断轮训 (heartbeat) 来获取任务，每次 heartbeat 中由 coordinator 扫描任务列表，检查是否有可分配的任务。这种架构下的代码逻辑将简洁很多，[详细可参考](https://github.com/OneSizeFitsQuorum/MIT6.824-2021/blob/master/docs/lab1.md)

* 模拟 mapReduce 的实际情况，在 coordinator 维护所有 worker 的状态，分别维护 空闲 worker 以及 繁忙 worker 缓存池，在 worker 掉线后将 worker 的任务放回未完成任务列表 (正常应该将任务立即分配给 空闲worker，由于 rpc 框架限制无法实现)

本实验采用方案2， 增加可拓展性

## 1. Worker

* HeartBeat + Report
  * hearbeat 发送心跳，根据 reply 选择 开启 mapTask、开启 reduceTask、Wait、exit
  * Report 在 reduce 或 map 执行完成后，发送 report 请求至 coordinator，进行结果的上报，由 coordinator 更新 task、worker 状态；

```go
// worker's heartbeat loop
//, continuely send heartbeat to server 

for {
    // resp contain the necessary message needed by map task and reduce task
    // some fileds' validity is corresponding to the jobtype
		resp := HeartBeat(args)
		switch resp.JobType {
		case MAP:
			invokeMap(mapf, resp)
		case REDUCE:
			invokeReduce(reducef, resp)
		case WAIT:
			time.Sleep(time.Second * 1)
		case EXIT:
			return
		}
	}
```

## 2. Coordinator

### 2.1 任务分发 以及 处理 worker report

HeartBeat：根据 未完成 map 任务数 决定给该任务分配 map、reduce 或 wait

Report：根据 reportType，记录 mapper 以及 reducer 上发的结果

StageChecker: 记录 mapreduce 任务当前所处的阶段，通过 channel 控制状态的切换

```go

func (c *Coordinator) HeartBeat(args *HeartBeatArgs, reply *HeartBeatReply) error {
  w := c.getWorker(args.Cookie)
  //logger.Printf("receive heartbeat from %d", w.cookie)
  // 读 mr 任务进度 + 具体任务处理应该是一个原子行为
  // 即 读取到一个 mr 任务进度后，必须要完整执行该状态下对应的 handler；
  // 否则一些 worker 会读到错的 mr 进度
  // 比如可能出现任务队列只剩一个任务，两个 worker 同时读到 MapProcess，导致panic
  c.mu.Lock()
  defer c.mu.Unlock()
  switch c.stage.tag {
  case MapProcess:
    c.handleMap(w, reply)
  case ReduceProcess:
    c.handleReduce(w, reply)
  case WaitForDoneProcess:
    c.handleWait(w, reply)
  case WaitForReduceProcess:
    c.handleWait(w, reply)
  case DoneProcess:
    c.handleDone(w, reply)
  }
  reply.NReduce = c.nReduce
  return nil
}
```

StageChecker 流转过程

* 通过 channel，每当有 map、reduce 任务下发或完成时，都向 channel 中发送一个信号。由 master 负责起一个后台协程监控这个 channel，当各信号到达一定数量后，轮转 master 状态。比如当 map 任务下发信号达到 map 任务总量时，master 状态应由 Process_Map 转为 Process_Wait，等待所有 mapper 返回结果

通过 channel 轮转状态，可能存在以下问题：

* 阻塞/~~非阻塞~~：若 channel 有缓冲，则可能出现 信号已发送，但状态未更新的 case，导致 heartBeat 读到错误状态而 panic
* 多个 worker 并发发送 hearBeat 时，需要保证各 worker 顺序访问 master 状态、获取资源（获取状态+获取资源是原子的）
  * 比如只剩最后一个 map task，但此时有两个 worker 读到了 Process_Map，此时会 panic
* master 的状态切换后台线程 与 heartBeat 线程应有 同步手段（存在 bad case 的可能，没触发过）
  * 比如 当 channel 的最后一个 map task 下发信号被状态线程读取后；下一个并发 heartbeat 请求立马读取 master 状态（状态未更新），此时读到的 master 状态也是错误的